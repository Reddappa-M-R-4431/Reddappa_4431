{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ae7ce40177087e2e5a2b6614a12a99225d2de094"
   },
   "source": [
    "# Boston Housing with Lasso Regression\n",
    "\n",
    "** With this data our objective is create a model using lasso regression to predict the houses price  **\n",
    "\n",
    "The data contains the following columns:\n",
    "* 'crim': per capita crime rate by town.\n",
    "* 'zn': proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "* 'indus': proportion of non-retail business acres per town.\n",
    "* 'chas':Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).\n",
    "* 'nox': nitrogen oxides concentration (parts per 10 million).\n",
    "* 'rm': average number of rooms per dwelling.\n",
    "* 'age': proportion of owner-occupied units built prior to 1940.\n",
    "* 'dis': weighted mean of distances to five Boston employment centres.\n",
    "* 'rad': index of accessibility to radial highways.\n",
    "* 'tax': full-value property-tax rate per $10,000.\n",
    "* 'ptratio': pupil-teacher ratio by town\n",
    "* 'black': 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town.\n",
    "* 'lstat': lower status of the population (percent).\n",
    "* 'medv': median value of owner-occupied homes in $$1000s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c45009768dc91bf48325ee04ab4b696521fc6220"
   },
   "source": [
    "**Lets Start**\n",
    "\n",
    "First we need to prepare our enviroment importing some librarys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "8f144cb466fa1333d41b2356f588ebacba2cab79"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "abda91c61669228e1b29c2fcb4816e5fbf114c7a"
   },
   "outputs": [],
   "source": [
    "# Importing DataSet and take a look at Data\n",
    "data = pd.read_csv(\"boston_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3844c8827b4e09d7e3a933976e04631cbdc53aef"
   },
   "source": [
    "** Here we can look at the data **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "24f0aae06fd2195aac00f39efb340e1230d5e255"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0.08829</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.012</td>\n",
       "      <td>66.6</td>\n",
       "      <td>5.5605</td>\n",
       "      <td>5</td>\n",
       "      <td>311</td>\n",
       "      <td>15.2</td>\n",
       "      <td>395.60</td>\n",
       "      <td>12.43</td>\n",
       "      <td>22.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID     crim    zn  indus  chas    nox     rm   age     dis  rad  tax  \\\n",
       "0   1  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296   \n",
       "1   2  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242   \n",
       "2   4  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222   \n",
       "3   5  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222   \n",
       "4   7  0.08829  12.5   7.87     0  0.524  6.012  66.6  5.5605    5  311   \n",
       "\n",
       "   ptratio   black  lstat  medv  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     18.7  394.63   2.94  33.4  \n",
       "3     18.7  396.90   5.33  36.2  \n",
       "4     15.2  395.60  12.43  22.9  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "c7cb828d2c731ea59a70f6b0a6fb114815fb3bc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 333 entries, 0 to 332\n",
      "Data columns (total 15 columns):\n",
      "ID         333 non-null int64\n",
      "crim       333 non-null float64\n",
      "zn         333 non-null float64\n",
      "indus      333 non-null float64\n",
      "chas       333 non-null int64\n",
      "nox        333 non-null float64\n",
      "rm         333 non-null float64\n",
      "age        333 non-null float64\n",
      "dis        333 non-null float64\n",
      "rad        333 non-null int64\n",
      "tax        333 non-null int64\n",
      "ptratio    333 non-null float64\n",
      "black      333 non-null float64\n",
      "lstat      333 non-null float64\n",
      "medv       333 non-null float64\n",
      "dtypes: float64(11), int64(4)\n",
      "memory usage: 39.1 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>333.000000</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>333.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>250.951952</td>\n",
       "      <td>3.360341</td>\n",
       "      <td>10.689189</td>\n",
       "      <td>11.293483</td>\n",
       "      <td>0.060060</td>\n",
       "      <td>0.557144</td>\n",
       "      <td>6.265619</td>\n",
       "      <td>68.226426</td>\n",
       "      <td>3.709934</td>\n",
       "      <td>9.633634</td>\n",
       "      <td>409.279279</td>\n",
       "      <td>18.448048</td>\n",
       "      <td>359.466096</td>\n",
       "      <td>12.515435</td>\n",
       "      <td>22.768769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>147.859438</td>\n",
       "      <td>7.352272</td>\n",
       "      <td>22.674762</td>\n",
       "      <td>6.998123</td>\n",
       "      <td>0.237956</td>\n",
       "      <td>0.114955</td>\n",
       "      <td>0.703952</td>\n",
       "      <td>28.133344</td>\n",
       "      <td>1.981123</td>\n",
       "      <td>8.742174</td>\n",
       "      <td>170.841988</td>\n",
       "      <td>2.151821</td>\n",
       "      <td>86.584567</td>\n",
       "      <td>7.067781</td>\n",
       "      <td>9.173468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>123.000000</td>\n",
       "      <td>0.078960</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.130000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.453000</td>\n",
       "      <td>5.884000</td>\n",
       "      <td>45.400000</td>\n",
       "      <td>2.122400</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>376.730000</td>\n",
       "      <td>7.180000</td>\n",
       "      <td>17.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>244.000000</td>\n",
       "      <td>0.261690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.202000</td>\n",
       "      <td>76.700000</td>\n",
       "      <td>3.092300</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>392.050000</td>\n",
       "      <td>10.970000</td>\n",
       "      <td>21.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>377.000000</td>\n",
       "      <td>3.678220</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.631000</td>\n",
       "      <td>6.595000</td>\n",
       "      <td>93.800000</td>\n",
       "      <td>5.116700</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.240000</td>\n",
       "      <td>16.420000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>73.534100</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.725000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>10.710300</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>21.200000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID        crim          zn       indus        chas         nox  \\\n",
       "count  333.000000  333.000000  333.000000  333.000000  333.000000  333.000000   \n",
       "mean   250.951952    3.360341   10.689189   11.293483    0.060060    0.557144   \n",
       "std    147.859438    7.352272   22.674762    6.998123    0.237956    0.114955   \n",
       "min      1.000000    0.006320    0.000000    0.740000    0.000000    0.385000   \n",
       "25%    123.000000    0.078960    0.000000    5.130000    0.000000    0.453000   \n",
       "50%    244.000000    0.261690    0.000000    9.900000    0.000000    0.538000   \n",
       "75%    377.000000    3.678220   12.500000   18.100000    0.000000    0.631000   \n",
       "max    506.000000   73.534100  100.000000   27.740000    1.000000    0.871000   \n",
       "\n",
       "               rm         age         dis         rad         tax     ptratio  \\\n",
       "count  333.000000  333.000000  333.000000  333.000000  333.000000  333.000000   \n",
       "mean     6.265619   68.226426    3.709934    9.633634  409.279279   18.448048   \n",
       "std      0.703952   28.133344    1.981123    8.742174  170.841988    2.151821   \n",
       "min      3.561000    6.000000    1.129600    1.000000  188.000000   12.600000   \n",
       "25%      5.884000   45.400000    2.122400    4.000000  279.000000   17.400000   \n",
       "50%      6.202000   76.700000    3.092300    5.000000  330.000000   19.000000   \n",
       "75%      6.595000   93.800000    5.116700   24.000000  666.000000   20.200000   \n",
       "max      8.725000  100.000000   10.710300   24.000000  711.000000   21.200000   \n",
       "\n",
       "            black       lstat        medv  \n",
       "count  333.000000  333.000000  333.000000  \n",
       "mean   359.466096   12.515435   22.768769  \n",
       "std     86.584567    7.067781    9.173468  \n",
       "min      3.500000    1.730000    5.000000  \n",
       "25%    376.730000    7.180000   17.400000  \n",
       "50%    392.050000   10.970000   21.600000  \n",
       "75%    396.240000   16.420000   25.000000  \n",
       "max    396.900000   37.970000   50.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.info()\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ac3e2547686ed620ba4749ef6f81635b1e5595a1"
   },
   "source": [
    "** Now, our goal is think about the columns, and discovery which columns is relevant to build our model, because if we consider to put columns with not relevant  with our objective \"medv\" the model may be not efficient **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "cbd32d564bbe45167243ce0b35d80781b18b94d4"
   },
   "outputs": [],
   "source": [
    "#ID columns does not relevant for our analysis.\n",
    "data.drop('ID', axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b98251ce12b200eedbaf510892a0d9b9899ca732"
   },
   "source": [
    "** Now lets take a loot how all the variables relate to each other. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "55c45be0eaeddb7a278e8d84c5468587b07b9333"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.corr of          crim    zn  indus  chas    nox     rm    age     dis  rad  tax  \\\n",
       "0     0.00632  18.0   2.31     0  0.538  6.575   65.2  4.0900    1  296   \n",
       "1     0.02731   0.0   7.07     0  0.469  6.421   78.9  4.9671    2  242   \n",
       "2     0.03237   0.0   2.18     0  0.458  6.998   45.8  6.0622    3  222   \n",
       "3     0.06905   0.0   2.18     0  0.458  7.147   54.2  6.0622    3  222   \n",
       "4     0.08829  12.5   7.87     0  0.524  6.012   66.6  5.5605    5  311   \n",
       "5     0.22489  12.5   7.87     0  0.524  6.377   94.3  6.3467    5  311   \n",
       "6     0.11747  12.5   7.87     0  0.524  6.009   82.9  6.2267    5  311   \n",
       "7     0.09378  12.5   7.87     0  0.524  5.889   39.0  5.4509    5  311   \n",
       "8     0.62976   0.0   8.14     0  0.538  5.949   61.8  4.7075    4  307   \n",
       "9     0.63796   0.0   8.14     0  0.538  6.096   84.5  4.4619    4  307   \n",
       "10    0.62739   0.0   8.14     0  0.538  5.834   56.5  4.4986    4  307   \n",
       "11    1.05393   0.0   8.14     0  0.538  5.935   29.3  4.4986    4  307   \n",
       "12    0.80271   0.0   8.14     0  0.538  5.456   36.6  3.7965    4  307   \n",
       "13    1.25179   0.0   8.14     0  0.538  5.570   98.1  3.7979    4  307   \n",
       "14    0.85204   0.0   8.14     0  0.538  5.965   89.2  4.0123    4  307   \n",
       "15    1.23247   0.0   8.14     0  0.538  6.142   91.7  3.9769    4  307   \n",
       "16    0.98843   0.0   8.14     0  0.538  5.813  100.0  4.0952    4  307   \n",
       "17    0.95577   0.0   8.14     0  0.538  6.047   88.8  4.4534    4  307   \n",
       "18    1.13081   0.0   8.14     0  0.538  5.713   94.1  4.2330    4  307   \n",
       "19    1.35472   0.0   8.14     0  0.538  6.072  100.0  4.1750    4  307   \n",
       "20    1.61282   0.0   8.14     0  0.538  6.096   96.9  3.7598    4  307   \n",
       "21    0.17505   0.0   5.96     0  0.499  5.966   30.2  3.8473    5  279   \n",
       "22    0.02763  75.0   2.95     0  0.428  6.595   21.8  5.4011    3  252   \n",
       "23    0.03359  75.0   2.95     0  0.428  7.024   15.8  5.4011    3  252   \n",
       "24    0.14150   0.0   6.91     0  0.448  6.169    6.6  5.7209    3  233   \n",
       "25    0.15936   0.0   6.91     0  0.448  6.211    6.5  5.7209    3  233   \n",
       "26    0.12269   0.0   6.91     0  0.448  6.069   40.0  5.7209    3  233   \n",
       "27    0.17142   0.0   6.91     0  0.448  5.682   33.8  5.1004    3  233   \n",
       "28    0.18836   0.0   6.91     0  0.448  5.786   33.3  5.1004    3  233   \n",
       "29    0.22927   0.0   6.91     0  0.448  6.030   85.5  5.6894    3  233   \n",
       "..        ...   ...    ...   ...    ...    ...    ...     ...  ...  ...   \n",
       "303   7.83932   0.0  18.10     0  0.655  6.209   65.4  2.9634   24  666   \n",
       "304   3.16360   0.0  18.10     0  0.655  5.759   48.2  3.0665   24  666   \n",
       "305   3.77498   0.0  18.10     0  0.655  5.952   84.7  2.8715   24  666   \n",
       "306   4.42228   0.0  18.10     0  0.584  6.003   94.5  2.5403   24  666   \n",
       "307  15.57570   0.0  18.10     0  0.580  5.926   71.0  2.9084   24  666   \n",
       "308  13.07510   0.0  18.10     0  0.580  5.713   56.7  2.8237   24  666   \n",
       "309   4.03841   0.0  18.10     0  0.532  6.229   90.7  3.0993   24  666   \n",
       "310   3.56868   0.0  18.10     0  0.580  6.437   75.0  2.8965   24  666   \n",
       "311   8.05579   0.0  18.10     0  0.584  5.427   95.4  2.4298   24  666   \n",
       "312   4.87141   0.0  18.10     0  0.614  6.484   93.6  2.3053   24  666   \n",
       "313  15.02340   0.0  18.10     0  0.614  5.304   97.3  2.1007   24  666   \n",
       "314  10.23300   0.0  18.10     0  0.614  6.185   96.7  2.1705   24  666   \n",
       "315  14.33370   0.0  18.10     0  0.614  6.229   88.0  1.9512   24  666   \n",
       "316   5.82401   0.0  18.10     0  0.532  6.242   64.7  3.4242   24  666   \n",
       "317   5.70818   0.0  18.10     0  0.532  6.750   74.9  3.3317   24  666   \n",
       "318   2.81838   0.0  18.10     0  0.532  5.762   40.3  4.0983   24  666   \n",
       "319   2.37857   0.0  18.10     0  0.583  5.871   41.9  3.7240   24  666   \n",
       "320   5.69175   0.0  18.10     0  0.583  6.114   79.8  3.5459   24  666   \n",
       "321   4.83567   0.0  18.10     0  0.583  5.905   53.2  3.1523   24  666   \n",
       "322   0.15086   0.0  27.74     0  0.609  5.454   92.7  1.8209    4  711   \n",
       "323   0.20746   0.0  27.74     0  0.609  5.093   98.0  1.8226    4  711   \n",
       "324   0.10574   0.0  27.74     0  0.609  5.983   98.8  1.8681    4  711   \n",
       "325   0.11132   0.0  27.74     0  0.609  5.983   83.5  2.1099    4  711   \n",
       "326   0.17331   0.0   9.69     0  0.585  5.707   54.0  2.3817    6  391   \n",
       "327   0.26838   0.0   9.69     0  0.585  5.794   70.6  2.8927    6  391   \n",
       "328   0.17783   0.0   9.69     0  0.585  5.569   73.5  2.3999    6  391   \n",
       "329   0.06263   0.0  11.93     0  0.573  6.593   69.1  2.4786    1  273   \n",
       "330   0.04527   0.0  11.93     0  0.573  6.120   76.7  2.2875    1  273   \n",
       "331   0.06076   0.0  11.93     0  0.573  6.976   91.0  2.1675    1  273   \n",
       "332   0.04741   0.0  11.93     0  0.573  6.030   80.8  2.5050    1  273   \n",
       "\n",
       "     ptratio   black  lstat  medv  \n",
       "0       15.3  396.90   4.98  24.0  \n",
       "1       17.8  396.90   9.14  21.6  \n",
       "2       18.7  394.63   2.94  33.4  \n",
       "3       18.7  396.90   5.33  36.2  \n",
       "4       15.2  395.60  12.43  22.9  \n",
       "5       15.2  392.52  20.45  15.0  \n",
       "6       15.2  396.90  13.27  18.9  \n",
       "7       15.2  390.50  15.71  21.7  \n",
       "8       21.0  396.90   8.26  20.4  \n",
       "9       21.0  380.02  10.26  18.2  \n",
       "10      21.0  395.62   8.47  19.9  \n",
       "11      21.0  386.85   6.58  23.1  \n",
       "12      21.0  288.99  11.69  20.2  \n",
       "13      21.0  376.57  21.02  13.6  \n",
       "14      21.0  392.53  13.83  19.6  \n",
       "15      21.0  396.90  18.72  15.2  \n",
       "16      21.0  394.54  19.88  14.5  \n",
       "17      21.0  306.38  17.28  14.8  \n",
       "18      21.0  360.17  22.60  12.7  \n",
       "19      21.0  376.73  13.04  14.5  \n",
       "20      21.0  248.31  20.34  13.5  \n",
       "21      19.2  393.43  10.13  24.7  \n",
       "22      18.3  395.63   4.32  30.8  \n",
       "23      18.3  395.62   1.98  34.9  \n",
       "24      17.9  383.37   5.81  25.3  \n",
       "25      17.9  394.46   7.44  24.7  \n",
       "26      17.9  389.39   9.55  21.2  \n",
       "27      17.9  396.90  10.21  19.3  \n",
       "28      17.9  396.90  14.15  20.0  \n",
       "29      17.9  392.74  18.80  16.6  \n",
       "..       ...     ...    ...   ...  \n",
       "303     20.2  396.90  13.22  21.4  \n",
       "304     20.2  334.40  14.13  19.9  \n",
       "305     20.2   22.01  17.15  19.0  \n",
       "306     20.2  331.29  21.32  19.1  \n",
       "307     20.2  368.74  18.13  19.1  \n",
       "308     20.2  396.90  14.76  20.1  \n",
       "309     20.2  395.33  12.87  19.6  \n",
       "310     20.2  393.37  14.36  23.2  \n",
       "311     20.2  352.58  18.14  13.8  \n",
       "312     20.2  396.21  18.68  16.7  \n",
       "313     20.2  349.48  24.91  12.0  \n",
       "314     20.2  379.70  18.03  14.6  \n",
       "315     20.2  383.32  13.11  21.4  \n",
       "316     20.2  396.90  10.74  23.0  \n",
       "317     20.2  393.07   7.74  23.7  \n",
       "318     20.2  392.92  10.42  21.8  \n",
       "319     20.2  370.73  13.34  20.6  \n",
       "320     20.2  392.68  14.98  19.1  \n",
       "321     20.2  388.22  11.45  20.6  \n",
       "322     20.1  395.09  18.06  15.2  \n",
       "323     20.1  318.43  29.68   8.1  \n",
       "324     20.1  390.11  18.07  13.6  \n",
       "325     20.1  396.90  13.35  20.1  \n",
       "326     19.2  396.90  12.01  21.8  \n",
       "327     19.2  396.90  14.10  18.3  \n",
       "328     19.2  395.77  15.10  17.5  \n",
       "329     21.0  391.99   9.67  22.4  \n",
       "330     21.0  396.90   9.08  20.6  \n",
       "331     21.0  396.90   5.64  23.9  \n",
       "332     21.0  396.90   7.88  11.9  \n",
       "\n",
       "[333 rows x 14 columns]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "908c140881f1efd1fb83e0d77283629868408fb4"
   },
   "source": [
    "# Trainning Lasso Regression Model\n",
    "**Define X and Y**\n",
    "\n",
    "X: Varibles named as predictors, independent variables, features.                                                               \n",
    "Y: Variable named as response or dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "47d0ed5d507fe7a9a077acbf9c21b9c096a21df4"
   },
   "outputs": [],
   "source": [
    "X = data[['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax',\n",
    "       'ptratio', 'black', 'lstat']]\n",
    "y = data['medv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "fe5a0141e68ec9e0d98b248bd0697ad8339df864"
   },
   "outputs": [],
   "source": [
    "train_index = int(0.8 * len(X))\n",
    "x_train, x_test = X[:train_index].values, X[train_index:].values\n",
    "y_train, y_test = y[:train_index].values, y[train_index:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "af6124c5bfc498be6a185b8fcbcf4cd0a257580f"
   },
   "outputs": [],
   "source": [
    "mean_X_train = np.mean(x_train)\n",
    "std_X_train = np.std(x_train)\n",
    "mean_X_test = np.mean(x_test)\n",
    "std_X_test = np.std(x_test)\n",
    "#Scaling the data without sklearn\n",
    "x_train = (x_train - mean_X_train) / std_X_train\n",
    "x_test = (x_test - mean_X_test) / std_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-4.95098762e-01, -3.61685657e-01, -4.78018259e-01,\n",
       "         -4.95145621e-01, -4.91156651e-01, -4.46395662e-01,\n",
       "         -1.17239732e-02, -4.64820551e-01, -4.87731179e-01,\n",
       "          1.69952934e+00, -3.81704651e-01,  2.44764659e+00,\n",
       "         -4.58221698e-01],\n",
       "        [-4.94943133e-01, -4.95145621e-01, -4.42725513e-01,\n",
       "         -4.95145621e-01, -4.91668247e-01, -4.47537486e-01,\n",
       "          8.98538884e-02, -4.58317344e-01, -4.80316736e-01,\n",
       "          1.29914945e+00, -3.63168545e-01,  2.44764659e+00,\n",
       "         -4.27377617e-01],\n",
       "        [-4.94905615e-01, -4.95145621e-01, -4.78982136e-01,\n",
       "         -4.95145621e-01, -4.91749806e-01, -4.43259353e-01,\n",
       "         -1.55564157e-01, -4.50197788e-01, -4.72902294e-01,\n",
       "          1.15086060e+00, -3.56495547e-01,  2.43081580e+00,\n",
       "         -4.73347160e-01],\n",
       "        [-4.94633654e-01, -4.95145621e-01, -4.78982136e-01,\n",
       "         -4.95145621e-01, -4.91749806e-01, -4.42154601e-01,\n",
       "         -9.32828401e-02, -4.50197788e-01, -4.72902294e-01,\n",
       "          1.15086060e+00, -3.56495547e-01,  2.44764659e+00,\n",
       "         -4.55626643e-01],\n",
       "        [-4.94491000e-01, -4.02465090e-01, -4.36793959e-01,\n",
       "         -4.95145621e-01, -4.91260453e-01, -4.50569993e-01,\n",
       "         -1.34375375e-03, -4.53917614e-01, -4.58073409e-01,\n",
       "          1.81074598e+00, -3.82446096e-01,  2.43800781e+00,\n",
       "         -4.02984101e-01]]),\n",
       " array([[-0.42142842, -0.46210117, -0.3626701 , -0.46210117, -0.45882159,\n",
       "         -0.43124458,  0.07570556, -0.45410988, -0.33025887,  3.19652275,\n",
       "         -0.3511339 ,  1.26635143, -0.31707464],\n",
       "        [-0.30468256, -0.46210117, -0.3626701 , -0.46210117, -0.45882159,\n",
       "         -0.43378254,  0.08724176, -0.45336991, -0.33025887,  3.19652275,\n",
       "         -0.3511339 ,  0.69684761, -0.35179311],\n",
       "        [-0.2107982 , -0.46210117, -0.3626701 , -0.46210117, -0.45829422,\n",
       "         -0.43727636,  0.08724176, -0.45299196, -0.33025887,  3.19652275,\n",
       "         -0.3511339 ,  0.02280384, -0.25895415],\n",
       "        [-0.3627547 , -0.46210117, -0.3626701 , -0.46210117, -0.45837113,\n",
       "         -0.42675645,  0.08724176, -0.45202237, -0.33025887,  3.19652275,\n",
       "         -0.3511339 , -0.31240522, -0.30251705],\n",
       "        [-0.31959832, -0.46210117, -0.3626701 , -0.46210117, -0.45837113,\n",
       "         -0.43296402,  0.02736338, -0.45305074, -0.33025887,  3.19652275,\n",
       "         -0.3511339 ,  0.23754199, -0.31575621]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:5] , x_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a class for Lasso Regression\n",
    "\n",
    "class Lasso_Regression():\n",
    "\n",
    "  #initiating the hyperparameters\n",
    "  def __init__(self, learning_rate, no_of_iterations, lambda_parameter):\n",
    "\n",
    "    self.learning_rate = learning_rate\n",
    "    self.no_of_iterations = no_of_iterations\n",
    "    self.lambda_parameter = lambda_parameter\n",
    "\n",
    "\n",
    "  # fitting the dataset to the Lasso Regression model\n",
    "  def fit(self, X, Y):\n",
    "\n",
    "    # m --> number of Data points --> number of rows\n",
    "    # n --> number of input features --> number of columns\n",
    "    self.m, self.n = X.shape\n",
    "\n",
    "    self.w = np.zeros(self.n)\n",
    "\n",
    "    self.b = 0\n",
    "\n",
    "    self.X = X\n",
    "\n",
    "    self.Y = Y\n",
    "\n",
    "    # implementing Gradient Descent algorithm for Optimization\n",
    "\n",
    "    for i in range(self.no_of_iterations):     # missed \"self\"\n",
    "      self.upadte_weights()\n",
    "\n",
    "\n",
    "  # function for updating the weight & bias value\n",
    "  def upadte_weights(self):\n",
    "\n",
    "    # linear equation of the model\n",
    "    Y_prediction = self.predict(self.X)\n",
    "\n",
    "    # gradients (dw, db)\n",
    "\n",
    "    # gradient for weight\n",
    "    dw = np.zeros(self.n)\n",
    "\n",
    "    for i in range(self.n):\n",
    "\n",
    "      if self.w[i]>0:\n",
    "\n",
    "        dw[i] = (-(2*(self.X[:,i]).dot(self.Y - Y_prediction)) + self.lambda_parameter) / self.m \n",
    "\n",
    "      else :\n",
    "\n",
    "        dw[i] = (-(2*(self.X[:,i]).dot(self.Y - Y_prediction)) - self.lambda_parameter) / self.m\n",
    "\n",
    "\n",
    "    # gradient for bias\n",
    "    db = - 2 * np.sum(self.Y - Y_prediction) / self.m\n",
    "\n",
    "\n",
    "    # updating the weights & bias\n",
    "\n",
    "    self.w = self.w - self.learning_rate*dw\n",
    "    self.b = self.b - self.learning_rate*db\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "  # Predicting the Target variable\n",
    "  def predict(self,X):\n",
    "\n",
    "    return X.dot(self.w) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Lasso_Regression( learning_rate = 0.01, no_of_iterations=1000,\n",
    "                        lambda_parameter= 0.98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score is  41.42\n"
     ]
    }
   ],
   "source": [
    "SSres = np.sum((y_test - y_pred)**2)\n",
    "y_pred_mean = np.mean(y_pred)\n",
    "SStot = np.sum((y_test - y_pred_mean)**2)\n",
    "r2 = 1 - SSres/SStot\n",
    "r2for = \"{:.2f}\".format(r2*100)\n",
    "print(\"r2_score is \" , r2for)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "7c77b4a60b955b84dbaa7a5d9355e80bd9708a9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute  error  2.70\n",
      "Root mean squared error  3.49\n",
      "Mean squared error  12.17\n"
     ]
    }
   ],
   "source": [
    "mae = np.mean(np.abs(y_test-y_pred))\n",
    "maefor = \"{:.2f}\".format(mae)\n",
    "print(\"Mean absolute  error \" , maefor)\n",
    "\n",
    "rmse = np.sqrt((np.sum((y_test-y_pred)**2))/len(y_test))\n",
    "rmsefor = \"{:.2f}\".format(rmse)\n",
    "print(\"Root mean squared error \" , rmsefor)\n",
    "\n",
    "mse = ((np.sum((y_test-y_pred)**2))/len(y_test))\n",
    "msefor = \"{:.2f}\".format(mse)\n",
    "print(\"Mean squared error \" , msefor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gridsearch():\n",
    "    \n",
    "\n",
    "# Model training    \n",
    "    max_accuracy = 0\n",
    "      \n",
    "    # learning_rate choices    \n",
    "    learning_rates = [ 0.1, 0.2, 0.3, 0.4, 0.5, \n",
    "                      0.01, 0.02, 0.03, 0.04, 0.05 ]\n",
    "      \n",
    "    # iterations choices    \n",
    "    no_of_iterations = [ 100, 200, 300, 400, 500 ]\n",
    "    \n",
    "    # lambda parameters\n",
    "    lambda_parameter = [0, 0.01, 0.98, 0.1, 0.5, 1, 10]\n",
    "      \n",
    "    # available combination of learning_rate and iterations\n",
    "      \n",
    "    parameters = []    \n",
    "    for i in learning_rates :        \n",
    "        for j in no_of_iterations : \n",
    "            for a in lambda_parameter:\n",
    "                parameters.append( ( i, j, a ) )\n",
    "              \n",
    "    #print(\"Available combinations : \",  parameters )\n",
    "              \n",
    "    # Applying linear searching in list of available combination\n",
    "    # to achieved maximum accuracy on CV set\n",
    "      \n",
    "    for k in range( len( parameters ) ) :        \n",
    "        model1 = Lasso_Regression( learning_rate = parameters[k][0], no_of_iterations = parameters[k][1], lambda_parameter = parameters[k][2])\n",
    "      \n",
    "        model1.fit( x_train, y_train )\n",
    "        \n",
    "        # Prediction on validation set\n",
    "        Y_pred = model1.predict( x_test )\n",
    "       \n",
    "        # measure performance  on validation set\n",
    "      \n",
    "        correctly_price = 0\n",
    "        count = 0\n",
    "      \n",
    "        for i in range( np.size(Y_pred) ) :            \n",
    "            if y_test[count] != Y_pred[count]:                  \n",
    "                SSres = np.sum((y_test - Y_pred)**2)\n",
    "                y_pred_mean = np.mean(Y_pred)\n",
    "                SStot = np.sum((y_test - y_pred_mean)**2)\n",
    "                r2 = 1 - SSres/SStot\n",
    "                \n",
    "                mae = np.mean(np.abs(y_test-y_pred))\n",
    "                maefor = \"{:.2f}\".format(mae)\n",
    "                #print(\"Mean absolute  error \" , maefor)\n",
    "\n",
    "                rmse = np.sqrt((np.sum((y_test-y_pred)**2))/len(y_test))\n",
    "                rmsefor = \"{:.2f}\".format(rmse)\n",
    "                #print(\"Root mean squared error \" , rmsefor)\n",
    "\n",
    "                mse = ((np.sum((y_test-y_pred)**2))/len(y_test))\n",
    "                msefor = \"{:.2f}\".format(mse)\n",
    "                #print(\"Mean squared error \" , msefor)\n",
    "               \n",
    "        curr_accuracy = ( r2) * 100\n",
    "        mae = mae \n",
    "        rmsefor = rmsefor\n",
    "        msefor = msefor\n",
    "                \n",
    "        r2_score = curr_accuracy\n",
    "              \n",
    "    print( \"Maximum accuracy achieved by our model through grid searching : \", r2_score )\n",
    "    print( \"The least mean Absolute error\", mae)\n",
    "    print( \"The least root mean squared error \" , rmsefor)\n",
    "    print( \"The mean squared error \" , msefor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum accuracy achieved by our model through grid searching :  46.279817356638084\n",
      "The least mean Absolute error 2.7022730417277074\n",
      "The least root mean squared error  3.49\n",
      "The mean squared error  12.17\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\" :     \n",
    "    Gridsearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 0.001\n",
      "mse 12.174046556501848\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def lasso_regression(X, y, alpha):\n",
    "    # Implementation of Lasso regression with a given regularization parameter alpha\n",
    "    # ...\n",
    "    beta = 0\n",
    "    return beta\n",
    "\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    # Implementation of mean squared error\n",
    "    # ...\n",
    "    return mse\n",
    "\n",
    "def random_search(X, y, alphas, n_iter):\n",
    "    # Implementation of RandomizedSearchCV for Lasso regression\n",
    "    best_mse = np.inf\n",
    "    best_alpha = None\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        alpha = np.random.choice(alphas)\n",
    "        beta = lasso_regression(X, y, alpha)\n",
    "        y_pred = X.dot(beta)\n",
    "        mse = mean_squared_error(y, y_pred)\n",
    "        \n",
    "        if mse < best_mse:\n",
    "            best_mse = mse\n",
    "            best_alpha = alpha\n",
    "    \n",
    "    return best_alpha\n",
    "\n",
    "# Generate some sample data\n",
    "np.random.seed(0)\n",
    "n = 100\n",
    "p = 10\n",
    "X = np.random.randn(n, p)\n",
    "y = np.random.randn(n)\n",
    "\n",
    "# Set up the hyperparameters to search over and the number of iterations\n",
    "alphas = np.logspace(-3, 3, num=7)\n",
    "n_iter = 100\n",
    "\n",
    "# Perform the random search\n",
    "best_alpha = random_search(X, y, alphas, n_iter)\n",
    "print(f\"Best alpha: {best_alpha}\")\n",
    "print(\"mse\",mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 2.15443\n",
      "Best R2 score: 45.42548\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define Ridge Regression function\n",
    "def Lasso_Regression(alpha, x_train, x_test, y_train, y_test):\n",
    "    # Fit Ridge Regression model with given alpha\n",
    "    model = np.linalg.inv(x_train.T.dot(x_train) + alpha*np.identity(x_train.shape[1])).dot(x_train.T).dot(y_train)\n",
    "    \n",
    "    # Predict on test set\n",
    "    y_pred = x_test.dot(model)\n",
    "    \n",
    "    # Calculate R2 score\n",
    "    r2 = 1 - np.sum((y_test - y_pred)**2) / np.sum((y_test -np.mean(y_test))**2)\n",
    "    \n",
    "    return r2\n",
    "\n",
    "# Define range of alpha values to search over\n",
    "alphas = np.logspace(-3, 3, num=100)\n",
    "\n",
    "# Define number of iterations for random search\n",
    "n_iter = 10\n",
    "\n",
    "# Initialize best hyperparameters and R2 score\n",
    "best_alpha = None\n",
    "best_r2 = -np.inf\n",
    "\n",
    "# Perform random search\n",
    "for i in range(n_iter):\n",
    "    # Select random alpha value\n",
    "    alpha = np.random.choice(alphas)\n",
    "    \n",
    "    # Compute R2 score for Ridge Regression with this alpha\n",
    "    r2 = Lasso_Regression(alpha, x_train, x_test, y_train, y_test)\n",
    "    \n",
    "    # Update best hyperparameters and R2 score if necessary\n",
    "    if r2 > best_r2:\n",
    "        best_alpha = alpha\n",
    "        best_r2 = r2\n",
    "        \n",
    "# Print best hyperparameters and R2 score\n",
    "print(\"Best alpha: {:.5f}\".format(best_alpha))\n",
    "print(\"Best R2 score: {:.5f}\".format(best_r2*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "643a47424beb36352ffe22be6206234b6bc868893f6b52b5682a155db092888b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
